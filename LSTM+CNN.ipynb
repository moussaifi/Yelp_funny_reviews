{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport string\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n'''from nltk.tokenize import WordPunctTokenizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n'''\nfrom sklearn.feature_extraction.text import CountVectorizer","execution_count":132,"outputs":[]},{"metadata":{"_uuid":"4c8b0a68b09ee8fecbbfccdbeb300b63205e542d","trusted":true},"cell_type":"code","source":"yelp_business = pd.read_json('../input/yelp_academic_dataset_business.json', lines=True)\nyelp_business.fillna('NA', inplace=True)\n# we want to make sure we only work with restaurants -- nothing else\nrestaurants = yelp_business[yelp_business['categories'].str.contains('Restaurants')]\nprint('Number of all businesses: ',yelp_business.shape[0])\nprint(f\"Shape of restaurants dataset{restaurants.shape}\")","execution_count":133,"outputs":[{"output_type":"stream","text":"Number of all businesses:  192609\nShape of restaurants dataset(59371, 14)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"yelp_business.head()","execution_count":134,"outputs":[{"output_type":"execute_result","execution_count":134,"data":{"text/plain":"                          address  ...  state\n0  2818 E Camino Acequia Drive     ...   AZ  \n1  30 Eglinton Avenue W            ...   ON  \n2  10110 Johnston Rd, Ste 15       ...   NC  \n3  15655 W Roosevelt St, Ste 237   ...   AZ  \n4  4209 Stuart Andrew Blvd, Ste F  ...   NC  \n\n[5 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>address</th>\n      <th>attributes</th>\n      <th>business_id</th>\n      <th>categories</th>\n      <th>city</th>\n      <th>hours</th>\n      <th>is_open</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>name</th>\n      <th>postal_code</th>\n      <th>review_count</th>\n      <th>stars</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2818 E Camino Acequia Drive</td>\n      <td>{'GoodForKids': 'False'}</td>\n      <td>1SWheh84yJXfytovILXOAQ</td>\n      <td>Golf, Active Life</td>\n      <td>Phoenix</td>\n      <td>NA</td>\n      <td>0</td>\n      <td>33.522143</td>\n      <td>-112.018481</td>\n      <td>Arizona Biltmore Golf Club</td>\n      <td>85016</td>\n      <td>5</td>\n      <td>3.0</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30 Eglinton Avenue W</td>\n      <td>{'RestaurantsReservations': 'True', 'GoodForMeal': '{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': True, 'brunch': False, 'breakfast': False}', 'BusinessParking': '{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}', 'Caters': 'True', 'NoiseLevel': 'u'loud'', 'RestaurantsTableService': 'True', 'RestaurantsTakeOut': 'True', 'RestaurantsPriceRange2': '2', 'OutdoorSeating': 'False', 'BikeParking': 'False', 'Ambience': '{'romantic': False, 'intimate': False, 'classy': False, 'hipster': False, 'divey': False, 'touristy': False, 'trendy': False, 'upscale': False, 'casual': True}', 'HasTV': 'False', 'WiFi': 'u'no'', 'GoodForKids': 'True', 'Alcohol': 'u'full_bar'', 'RestaurantsAttire': 'u'casual'', 'RestaurantsGoodForGroups': 'True', 'RestaurantsDelivery': 'False'}</td>\n      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n      <td>Specialty Food, Restaurants, Dim Sum, Imported Food, Food, Chinese, Ethnic Food, Seafood</td>\n      <td>Mississauga</td>\n      <td>{'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'Wednesday': '9:0-0:0', 'Thursday': '9:0-0:0', 'Friday': '9:0-1:0', 'Saturday': '9:0-1:0', 'Sunday': '9:0-0:0'}</td>\n      <td>1</td>\n      <td>43.605499</td>\n      <td>-79.652289</td>\n      <td>Emerald Chinese Restaurant</td>\n      <td>L5R 3E7</td>\n      <td>128</td>\n      <td>2.5</td>\n      <td>ON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10110 Johnston Rd, Ste 15</td>\n      <td>{'GoodForKids': 'True', 'NoiseLevel': 'u'average'', 'RestaurantsDelivery': 'False', 'GoodForMeal': '{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': True, 'brunch': False, 'breakfast': False}', 'Alcohol': 'u'beer_and_wine'', 'Caters': 'False', 'WiFi': 'u'no'', 'RestaurantsTakeOut': 'True', 'BusinessAcceptsCreditCards': 'True', 'Ambience': '{'romantic': False, 'intimate': False, 'touristy': False, 'hipster': False, 'divey': False, 'classy': False, 'trendy': False, 'upscale': False, 'casual': True}', 'BusinessParking': '{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}', 'RestaurantsTableService': 'True', 'RestaurantsGoodForGroups': 'True', 'OutdoorSeating': 'False', 'HasTV': 'True', 'BikeParking': 'True', 'RestaurantsReservations': 'True', 'RestaurantsPriceRange2': '2', 'RestaurantsAttire': ''casual''}</td>\n      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n      <td>Sushi Bars, Restaurants, Japanese</td>\n      <td>Charlotte</td>\n      <td>{'Monday': '17:30-21:30', 'Wednesday': '17:30-21:30', 'Thursday': '17:30-21:30', 'Friday': '17:30-22:0', 'Saturday': '17:30-22:0', 'Sunday': '17:30-21:0'}</td>\n      <td>1</td>\n      <td>35.092564</td>\n      <td>-80.859132</td>\n      <td>Musashi Japanese Restaurant</td>\n      <td>28210</td>\n      <td>170</td>\n      <td>4.0</td>\n      <td>NC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15655 W Roosevelt St, Ste 237</td>\n      <td>NA</td>\n      <td>xvX2CttrVhyG2z1dFg_0xw</td>\n      <td>Insurance, Financial Services</td>\n      <td>Goodyear</td>\n      <td>{'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', 'Wednesday': '8:0-17:0', 'Thursday': '8:0-17:0', 'Friday': '8:0-17:0'}</td>\n      <td>1</td>\n      <td>33.455613</td>\n      <td>-112.395596</td>\n      <td>Farmers Insurance - Paul Lorenz</td>\n      <td>85338</td>\n      <td>3</td>\n      <td>5.0</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4209 Stuart Andrew Blvd, Ste F</td>\n      <td>{'BusinessAcceptsBitcoin': 'False', 'ByAppointmentOnly': 'True', 'BusinessAcceptsCreditCards': 'True'}</td>\n      <td>HhyxOkGAM07SRYtlQ4wMFQ</td>\n      <td>Plumbing, Shopping, Local Services, Home Services, Kitchen &amp; Bath, Home &amp; Garden, Water Heater Installation/Repair</td>\n      <td>Charlotte</td>\n      <td>{'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', 'Wednesday': '7:0-23:0', 'Thursday': '7:0-23:0', 'Friday': '7:0-23:0', 'Saturday': '7:0-23:0', 'Sunday': '7:0-23:0'}</td>\n      <td>1</td>\n      <td>35.190012</td>\n      <td>-80.887223</td>\n      <td>Queen City Plumbing</td>\n      <td>28217</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>NC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"restaurants.head()","execution_count":135,"outputs":[{"output_type":"execute_result","execution_count":135,"data":{"text/plain":"                         address  ...  state\n1   30 Eglinton Avenue W          ...   ON  \n2   10110 Johnston Rd, Ste 15     ...   NC  \n11  2450 E Indian School Rd       ...   AZ  \n13  5981 Andrews Rd               ...   OH  \n17  1775 E Tropicana Ave, Ste 29  ...   NV  \n\n[5 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>address</th>\n      <th>attributes</th>\n      <th>business_id</th>\n      <th>categories</th>\n      <th>city</th>\n      <th>hours</th>\n      <th>is_open</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>name</th>\n      <th>postal_code</th>\n      <th>review_count</th>\n      <th>stars</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>30 Eglinton Avenue W</td>\n      <td>{'RestaurantsReservations': 'True', 'GoodForMeal': '{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': True, 'brunch': False, 'breakfast': False}', 'BusinessParking': '{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}', 'Caters': 'True', 'NoiseLevel': 'u'loud'', 'RestaurantsTableService': 'True', 'RestaurantsTakeOut': 'True', 'RestaurantsPriceRange2': '2', 'OutdoorSeating': 'False', 'BikeParking': 'False', 'Ambience': '{'romantic': False, 'intimate': False, 'classy': False, 'hipster': False, 'divey': False, 'touristy': False, 'trendy': False, 'upscale': False, 'casual': True}', 'HasTV': 'False', 'WiFi': 'u'no'', 'GoodForKids': 'True', 'Alcohol': 'u'full_bar'', 'RestaurantsAttire': 'u'casual'', 'RestaurantsGoodForGroups': 'True', 'RestaurantsDelivery': 'False'}</td>\n      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n      <td>Specialty Food, Restaurants, Dim Sum, Imported Food, Food, Chinese, Ethnic Food, Seafood</td>\n      <td>Mississauga</td>\n      <td>{'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'Wednesday': '9:0-0:0', 'Thursday': '9:0-0:0', 'Friday': '9:0-1:0', 'Saturday': '9:0-1:0', 'Sunday': '9:0-0:0'}</td>\n      <td>1</td>\n      <td>43.605499</td>\n      <td>-79.652289</td>\n      <td>Emerald Chinese Restaurant</td>\n      <td>L5R 3E7</td>\n      <td>128</td>\n      <td>2.5</td>\n      <td>ON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10110 Johnston Rd, Ste 15</td>\n      <td>{'GoodForKids': 'True', 'NoiseLevel': 'u'average'', 'RestaurantsDelivery': 'False', 'GoodForMeal': '{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': True, 'brunch': False, 'breakfast': False}', 'Alcohol': 'u'beer_and_wine'', 'Caters': 'False', 'WiFi': 'u'no'', 'RestaurantsTakeOut': 'True', 'BusinessAcceptsCreditCards': 'True', 'Ambience': '{'romantic': False, 'intimate': False, 'touristy': False, 'hipster': False, 'divey': False, 'classy': False, 'trendy': False, 'upscale': False, 'casual': True}', 'BusinessParking': '{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}', 'RestaurantsTableService': 'True', 'RestaurantsGoodForGroups': 'True', 'OutdoorSeating': 'False', 'HasTV': 'True', 'BikeParking': 'True', 'RestaurantsReservations': 'True', 'RestaurantsPriceRange2': '2', 'RestaurantsAttire': ''casual''}</td>\n      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n      <td>Sushi Bars, Restaurants, Japanese</td>\n      <td>Charlotte</td>\n      <td>{'Monday': '17:30-21:30', 'Wednesday': '17:30-21:30', 'Thursday': '17:30-21:30', 'Friday': '17:30-22:0', 'Saturday': '17:30-22:0', 'Sunday': '17:30-21:0'}</td>\n      <td>1</td>\n      <td>35.092564</td>\n      <td>-80.859132</td>\n      <td>Musashi Japanese Restaurant</td>\n      <td>28210</td>\n      <td>170</td>\n      <td>4.0</td>\n      <td>NC</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2450 E Indian School Rd</td>\n      <td>{'RestaurantsTakeOut': 'True', 'BusinessParking': '{'garage': False, 'street': False, 'validated': False, 'lot': False, 'valet': False}', 'WiFi': 'u'no'', 'RestaurantsDelivery': 'False', 'OutdoorSeating': 'False', 'RestaurantsAttire': 'u'casual'', 'BusinessAcceptsCreditCards': 'True', 'RestaurantsGoodForGroups': 'True', 'RestaurantsReservations': 'False', 'HasTV': 'False', 'Ambience': '{'romantic': False, 'intimate': False, 'touristy': False, 'hipster': False, 'divey': False, 'classy': False, 'trendy': False, 'upscale': False, 'casual': False}', 'Alcohol': 'u'none'', 'RestaurantsPriceRange2': '1', 'GoodForKids': 'True'}</td>\n      <td>1Dfx3zM-rW4n-31KeC8sJg</td>\n      <td>Restaurants, Breakfast &amp; Brunch, Mexican, Tacos, Tex-Mex, Fast Food</td>\n      <td>Phoenix</td>\n      <td>{'Monday': '7:0-0:0', 'Tuesday': '7:0-0:0', 'Wednesday': '7:0-0:0', 'Thursday': '7:0-1:0', 'Friday': '7:0-1:0', 'Saturday': '7:0-1:0', 'Sunday': '7:0-0:0'}</td>\n      <td>1</td>\n      <td>33.495194</td>\n      <td>-112.028588</td>\n      <td>Taco Bell</td>\n      <td>85016</td>\n      <td>18</td>\n      <td>3.0</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>5981 Andrews Rd</td>\n      <td>{'RestaurantsPriceRange2': '2', 'BusinessAcceptsCreditCards': 'True', 'GoodForKids': 'True', 'RestaurantsDelivery': 'True', 'Alcohol': 'u'none'', 'OutdoorSeating': 'False', 'RestaurantsGoodForGroups': 'True', 'RestaurantsTakeOut': 'True', 'RestaurantsReservations': 'False', 'BikeParking': 'True', 'RestaurantsAttire': 'u'casual'', 'Ambience': 'None', 'BusinessParking': 'None'}</td>\n      <td>fweCYi8FmbJXHCqLnwuk8w</td>\n      <td>Italian, Restaurants, Pizza, Chicken Wings</td>\n      <td>Mentor-on-the-Lake</td>\n      <td>{'Monday': '10:0-0:0', 'Tuesday': '10:0-0:0', 'Wednesday': '10:0-0:0', 'Thursday': '10:0-0:0', 'Friday': '10:0-1:0', 'Saturday': '10:0-1:0', 'Sunday': '10:0-0:0'}</td>\n      <td>1</td>\n      <td>41.708520</td>\n      <td>-81.359556</td>\n      <td>Marco's Pizza</td>\n      <td>44060</td>\n      <td>16</td>\n      <td>4.0</td>\n      <td>OH</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1775 E Tropicana Ave, Ste 29</td>\n      <td>{'OutdoorSeating': 'False', 'BusinessAcceptsCreditCards': 'True', 'RestaurantsDelivery': 'False', 'RestaurantsReservations': 'True', 'RestaurantsAttire': ''casual'', 'Ambience': '{'romantic': True, 'intimate': False, 'touristy': False, 'hipster': False, 'divey': False, 'classy': True, 'trendy': False, 'upscale': False, 'casual': False}', 'HasTV': 'False', 'BYOBCorkage': ''no'', 'NoiseLevel': 'u'quiet'', 'RestaurantsTakeOut': 'True', 'RestaurantsPriceRange2': '2', 'RestaurantsGoodForGroups': 'True', 'WiFi': 'u'no'', 'Caters': 'True', 'GoodForKids': 'True', 'Alcohol': 'u'full_bar'', 'BusinessParking': '{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}'}</td>\n      <td>PZ-LZzSlhSe9utkQYU8pFg</td>\n      <td>Restaurants, Italian</td>\n      <td>Las Vegas</td>\n      <td>NA</td>\n      <td>0</td>\n      <td>36.100016</td>\n      <td>-115.128529</td>\n      <td>Carluccio's Tivoli Gardens</td>\n      <td>89119</td>\n      <td>40</td>\n      <td>4.0</td>\n      <td>NV</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"2a6fee5c004788aaff55656025270d0adf7c3747"},"cell_type":"markdown","source":"Now we bring the reviews and perform some preprocessing on those reviews.."},{"metadata":{"_uuid":"508d28c7fdb9065e3dbaf0a39472297fc3b292cf","trusted":true},"cell_type":"code","source":"yelp_review_iter = pd.read_json('../input/yelp_academic_dataset_review.json', chunksize=100000, lines=True)","execution_count":136,"outputs":[]},{"metadata":{"_uuid":"c6689f58f21411bac18026ba6edfbd0248a8b2f8"},"cell_type":"markdown","source":"Because reviews are too big, we will read them in chunks, and make sure we delete reviews of places that are not in our list of businesses filtered earlier. Note here we choose 5 chunks, but we could have chosen any number (larger numbers will give MemoryError later on)."},{"metadata":{"_uuid":"70007e05b3f8828eb82cc4c4f926f8e657861adb","trusted":true,"collapsed":true},"cell_type":"code","source":"yelp_review = pd.DataFrame()\ni=0\nfor df in yelp_review_iter:\n    \n    df = df[df['business_id'].isin(restaurants['business_id'])]\n    print(df.shape)\n    yelp_review = pd.concat([yelp_review, df])\n    print(i)\n    if i==70: break\n    i=i+1","execution_count":137,"outputs":[{"output_type":"stream","text":"(63667, 9)\n0\n(63513, 9)\n1\n(63553, 9)\n2\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-137-176eefe68184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0myelp_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myelp_review_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestaurants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0mlines_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_combine_lines\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;34m\"\"\"Combines a list of JSON objects into one JSON object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'['\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m']'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;34m\"\"\"Combines a list of JSON objects into one JSON object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'['\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m']'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"yelp_review.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85169d7858504ee719c36e795ba46f8eb9a3c909"},"cell_type":"markdown","source":"Also make sure we only get businesses that already show up in our review list and delete the rest."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nyelp_review.to_pickle(\"pickled_reviews.pickle\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews =pd.read_pickle(\"pickled_reviews.pickle\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1aad8f5fe22db8c3940e07fc3ae49d94000725bf","trusted":true},"cell_type":"code","source":"yelp_business = yelp_business[yelp_business['business_id'].isin(rest_reviews['business_id'])]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6385a3d6f0f21f722925451ecf38ff5c90647b21","trusted":true},"cell_type":"code","source":"print('Final businesses shape: ', yelp_business.shape)\nprint('Final review shape: ', rest_reviews.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews['funny'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_seq_items = 2000\nprint(rest_reviews[rest_reviews['funny']==1290][['business_id', 'text']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check:\nprint( (rest_reviews['funny']>4).mean())\nprint(f\"Number of funny reviews:{(rest_reviews['funny']>4).sum()}\")\n#print(rest_reviews['fun_bin'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"75269/4201684","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews['fun_bin']=rest_reviews['funny'].apply(lambda x: 1 if x>4 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rest_reviews['fun_bin'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Getting a df with funny reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews_fun = rest_reviews[rest_reviews['fun_bin']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews_fun.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews_fun.drop_duplicates(subset= 'text', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews_fun.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sampling not funny reviews\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews_not_fun = rest_reviews[rest_reviews['fun_bin']==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = rest_reviews_not_fun.index.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Balancing the classes: getting the same number of not funny reviews as funny\n#random_hotels = np.random.choice(neg_activity_df[\"hotel\"].unique(), len(neg_activity_df))\nrandom_idx = np.random.choice(idx,rest_reviews_fun.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(random_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews_not_fun = rest_reviews_not_fun.loc[random_idx,:].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_reviews_not_fun.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_final = pd.concat([rest_reviews_fun, rest_reviews_not_fun])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_final.to_csv(\"../balanced_reviews.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_final = pd.read_csv(\"../balanced_reviews.csv\", index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews = reviews_final[['funny','text', 'fun_bin']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_colwidth', -1)\ndf_reviews.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data pre-processing"},{"metadata":{},"cell_type":"markdown","source":"#### Goals\n- Keep punctuation\n- Split by \".\", \"!\" to account for misspeling (like \"Hi!I went to...\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install spacymoji","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom string import punctuation\nimport os\nimport spacy\nimport string\nimport re\nfrom spacy.symbols import ORTH\nfrom collections import Counter\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \nfrom spacymoji import Emoji","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nre_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\ndef sub_br(x): return re_br.sub(\"\\n\", x)\n\n#nlp = spacy.load(\"en\")\nnlp = spacy.load('en_core_web_sm')\nspacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n\nspacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n\ndef clean_text(text):\n    ''' Pre process and convert texts to a list of words '''\n    text = str(text)\n    text = text.lower()\n\n    # Clean the text\n   # text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=\\(\\)]\", \" \", text) # keep punctuatuin, numnbers and letters\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\",\", \" \", text)\n    text = re.sub(r\"\\.\", \" . \", text) #Add space to the dot\n    text = re.sub(r\"!\", \" ! \", text) #Add space to the exclamation sign\n    text = re.sub(r\":\", \" :\", text) #Add space before : sign\n    text = re.sub(r\";\", \" ;\", text) #Add space before ; sign\n    text = re.sub(r\"\\/\", \" \", text)\n    text = re.sub(r\"\\^\", \" ^ \", text)\n    text = re.sub(r\"\\+\", \" + \", text)\n    text = re.sub(r\"\\-\", \" - \", text)\n    text = re.sub(r\"\\=\", \" = \", text)\n    text = re.sub(r\"'\", \" \", text)\n    #text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n    #text = re.sub(r\":\", \" : \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\" u s \", \" american \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e - mail\", \"email\", text)\n    text = re.sub(r\"j k\", \"jk\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    # find emojis\n    emoji_list = []\n    '''\n    for word in text.split():\n        if any(char in emoji.UNICODE_EMOJI for char in word):\n            emoji_list.append(word)\n    emoji_list'''\n    #text = text.split()\n\n    return text\n\nmy_tok = spacy.load('en')\nemoji = Emoji(my_tok)\nmy_tok.add_pipe(emoji, first=True)\ndef spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(clean_text(x))]\n\ndef remove_stop_words(tokens): return [tok for tok in tokens if tok not in spacy_stopwords]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \"I'm soooo excited!!!!!This is 10000% the best place on earth:))))) 😃...\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_text(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spacy_tok(clean_text(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text2 = \"I also ordered a jade chicken quesadilla on the side.\\n\\nI'm gonna admit, this place looks kinda dirty. I don't think Arizona uses those health department letter grade system like California does, but if I were to just judge by how it looked inside, i'd give it a 'C' grade lol 😃\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"remove_stop_words(spacy_tok(clean_text(text2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building a vocabulary"},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = Counter()\nfor sent in df_reviews['text']:\n    try:\n        counts.update(remove_stop_words(spacy_tok(sent)))\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlen(counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vocabulary\nvocab2index = {\"\":0, \"UNK\":1}\nwords = [\"\", \"UNK\"]\nfor word in counts:\n    vocab2index[word] = len(words)\n    words.append(word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reviews['len_text'] = df_reviews['text'].apply(lambda x: len(x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WHat is the 99% quantile of  length of the sentence?\ndf_reviews['len_text'].quantile(0.99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WHat is the 95% quantile of  length of the sentence?\ndf_reviews['len_text'].quantile(0.95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# note that spacy_tok takes a while run it just once\ndef encode_sentence(sent, vocab2index, N=500, padding_start=True):\n    \"Encoding a sentence adding padding\"\n    x = remove_stop_words(spacy_tok(sent))\n    enc = np.zeros(N, dtype=np.int32)\n    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n    l = min(N, len(enc1))\n    if padding_start:\n        enc[:l] = enc1[:l]\n    else:\n        enc[N-l:] = enc1[:l]\n    return enc, l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l1 = [encode_sentence(sent, vocab2index, N=600, padding_start=False) for sent in df_reviews['text'][:5]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting into train and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" X_train, X_valid, y_train, y_valid = train_test_split(df_reviews['text'], df_reviews['fun_bin'], test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.reset_index(inplace=True, drop=True)\nX_valid.reset_index(inplace=True, drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.reset_index(inplace=True, drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_valid.reset_index(inplace=True, drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Writing a dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class YelpDataset(Dataset):\n    def __init__(self, df, y, N=500, padding_start=True):\n        self.df = df\n        self.X = [encode_sentence(sent, vocab2index, N, padding_start) for sent in self.df]\n        self.y = y\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        x, s = self.X[idx]\n        return x, s, self.y[idx]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds =  YelpDataset(X_train, y_train, padding_start=False)\nvalid_ds =  YelpDataset(X_valid, y_valid, padding_start=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check training and validation datasets for empty sentences"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training\nneg=[]\ni=0\nfor x,s,y in train_ds:\n    if s <=0:\n        neg.append(i)\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# validation\nneg=[]\ni=0\nfor x,s,y in valid_ds:\n    if s <=0:\n        neg.append(i)\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[[111618, 118582]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds[118582]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds[111618]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop([111618, 118582], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.drop([111618, 118582], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds =  YelpDataset(X_train, y_train, padding_start=False)\nvalid_ds =  YelpDataset(X_valid, y_valid, padding_start=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds[118582]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 500\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.where(df_reviews.isna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LSTM_CNN(torch.nn.Module) :\n    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n        super(LSTM_CNN,self).__init__()\n        self.hidden_dim = hidden_dim\n        self.dropout = nn.Dropout(0.5)\n        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.conv_3 = nn.Conv1d(in_channels=hidden_dim, out_channels=100, kernel_size=3)\n        self.conv_4 = nn.Conv1d(in_channels=hidden_dim, out_channels=100, kernel_size=4)\n        self.conv_5 = nn.Conv1d(in_channels=hidden_dim, out_channels=100, kernel_size=5)\n        self.linear = nn.Linear(403, 1)        \n        \n    def forward(self, x, s):\n        # sorting\n        s, sort_index = torch.sort(s.float(), 0,descending=True) # s is the length of the sentence. Sort these lengths\n        s = s.numpy().tolist() # \n        x_lstm = x[sort_index]\n        x_lstm = self.embeddings(x_lstm)\n        x_lstm = self.dropout(x_lstm)\n        x_pack = pack_padded_sequence(x_lstm, s, batch_first=True) # We want LSTM to forget the padding, but in order to apply \n        #ordering mini batches withtin the model\n        out_pack, (ht, ct) = self.lstm(x_pack) \n        #out_lstm = self.linear(ht[-1]) # Problem here is that output is not sorted!\n        #out_lstm = torch.zeros_like(out_lstm).scatter_(0, sort_index.unsqueeze(1).cuda(), out_lstm)\n        # scatter_ is undoing the sorting with the given sorting index\n        # kind of sorting back with the original indexing\n        x_cnn = self.embeddings(x)\n        #print(x_cnn.size())\n        x_cnn = x_cnn.transpose(1,2)\n        #print(x_cnn.size())\n        x3 = F.relu(self.conv_3(x_cnn))\n        x4 = F.relu(self.conv_4(x_cnn))\n        x5 = F.relu(self.conv_5(x_cnn))\n        x3 = nn.MaxPool1d(kernel_size = 398)(x3)\n        x4 = nn.MaxPool1d(kernel_size = 397)(x4)\n        x5 = nn.MaxPool1d(kernel_size = 396)(x5)\n        out_cnn = torch.cat([x3, x4, x5], 2)\n        #print(out_cnn.size())\n        out_cnn = out_cnn.view(out_cnn.size(0), -1)\n        out = torch.cat([out_cnn, ht[-1]],1)\n        out = self.dropout(out)\n        #print(out.size())\n        out = self.linear(out)\n        return out \n        ","execution_count":171,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_metrics(m, valid_dl):\n    model.eval()\n    correct = 0\n    total = 0\n    sum_loss = 0.0\n    for x, s, y in valid_dl:\n        x = x.long().cuda()\n        y = y.float().cuda().unsqueeze(1)\n        y_hat = model(x,s)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n        y_pred = y_hat > 0\n        correct += (y_pred.float() == y).float().sum()\n        total += y.shape[0]\n        sum_loss += loss.item()*y.shape[0]\n    return sum_loss/total, correct/total","execution_count":174,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_epocs(model, epochs=10, lr=0.001):\n    parameters = filter(lambda p: p.requires_grad, model.parameters())\n    optimizer = torch.optim.Adam(parameters, lr=lr)\n    for i in range(epochs):\n        model.train()\n        sum_loss = 0.0\n        total = 0\n        for x, s, y in train_dl:\n            x = x.long().cuda()\n            y = y.float().cuda()\n            y_pred = model(x, s)\n            optimizer.zero_grad()\n            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n            loss.backward()\n            optimizer.step()\n            sum_loss += loss.item()*y.shape[0]\n            total += y.shape[0]\n        val_loss, val_acc = val_metrics(model, valid_dl)\n        print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(m, p): torch.save(m.state_dict(), p)\n    \ndef load_model(m, p): m.load_state_dict(torch.load(p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(words)\nprint(vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LSTM_CNN(vocab_size, 103,103).cuda()","execution_count":172,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epocs(model, epochs=5, lr=0.01)","execution_count":175,"outputs":[{"output_type":"stream","text":"train loss 0.599 val loss 0.580 and val accuracy 0.705\ntrain loss 0.553 val loss 0.685 and val accuracy 0.718\ntrain loss 0.519 val loss 0.695 and val accuracy 0.714\ntrain loss 0.486 val loss 0.890 and val accuracy 0.713\ntrain loss 0.467 val loss 0.971 and val accuracy 0.701\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_model(model, '../model_lr0.01_5.pth')","execution_count":176,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epocs(model, epochs=5, lr=0.001)","execution_count":177,"outputs":[{"output_type":"stream","text":"train loss 0.440 val loss 1.139 and val accuracy 0.709\ntrain loss 0.430 val loss 1.216 and val accuracy 0.709\ntrain loss 0.424 val loss 1.365 and val accuracy 0.710\ntrain loss 0.421 val loss 1.443 and val accuracy 0.709\ntrain loss 0.418 val loss 1.598 and val accuracy 0.711\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_model(model, '../model_lr0.001_5.pth')","execution_count":178,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epocs(model, epochs=5, lr=0.0001)","execution_count":179,"outputs":[{"output_type":"stream","text":"train loss 0.416 val loss 1.556 and val accuracy 0.709\ntrain loss 0.415 val loss 1.560 and val accuracy 0.708\ntrain loss 0.415 val loss 1.582 and val accuracy 0.709\ntrain loss 0.415 val loss 1.596 and val accuracy 0.709\ntrain loss 0.414 val loss 1.606 and val accuracy 0.708\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_model(model, '../model_lr0.0001_5.pth')","execution_count":180,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epocs(model, epochs=5, lr=0.001)","execution_count":181,"outputs":[{"output_type":"stream","text":"train loss 0.415 val loss 1.711 and val accuracy 0.706\ntrain loss 0.413 val loss 1.883 and val accuracy 0.709\ntrain loss 0.411 val loss 1.890 and val accuracy 0.708\ntrain loss 0.410 val loss 2.097 and val accuracy 0.709\ntrain loss 0.409 val loss 2.175 and val accuracy 0.707\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epocs(model, epochs=5, lr=0.01)","execution_count":182,"outputs":[{"output_type":"stream","text":"train loss 0.444 val loss 2.474 and val accuracy 0.703\ntrain loss 0.473 val loss 2.496 and val accuracy 0.707\ntrain loss 0.471 val loss 2.204 and val accuracy 0.700\ntrain loss 0.459 val loss 2.442 and val accuracy 0.694\ntrain loss 0.455 val loss 3.331 and val accuracy 0.707\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epocs(model, epochs=5, lr=0.001)","execution_count":183,"outputs":[{"output_type":"stream","text":"train loss 0.436 val loss 3.113 and val accuracy 0.706\ntrain loss 0.424 val loss 3.092 and val accuracy 0.703\ntrain loss 0.419 val loss 3.218 and val accuracy 0.707\ntrain loss 0.415 val loss 3.371 and val accuracy 0.706\ntrain loss 0.414 val loss 3.437 and val accuracy 0.706\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}